{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5hOgUrd0AoyScfGRSYoOr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NXjuBi1dPqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Caynm9wDezfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8b848183-e765-4169-c9bb-2331aad35bda"
      },
      "source": [
        "#import data\n",
        "df = pd.read_csv('SMSSpamCollection', encoding = 'latin_1', sep='\\t', header = None)\n",
        "df.columns = ['label', 'message']\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPmgLp8l1ZNk",
        "colab_type": "text"
      },
      "source": [
        "Investigate the data a little bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5DRjEHUgip2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7979f0da-4d7f-441e-fb31-17b342d57eb2"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOtZkd4Vh9fO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "2789731b-7c8d-42e5-ecfc-cab4dfe4df1a"
      },
      "source": [
        "df[df['label']=='spam'].head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>spam</td>\n",
              "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>spam</td>\n",
              "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>spam</td>\n",
              "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>spam</td>\n",
              "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>spam</td>\n",
              "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>spam</td>\n",
              "      <td>07732584351 - Rodger Burns - MSG = We tried to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "8   spam  WINNER!! As a valued network customer you have...\n",
              "9   spam  Had your mobile 11 months or more? U R entitle...\n",
              "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
              "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
              "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
              "19  spam  England v Macedonia - dont miss the goals/team...\n",
              "34  spam  Thanks for your subscription to Ringtone UK yo...\n",
              "42  spam  07732584351 - Rodger Burns - MSG = We tried to..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rReIvw4_h9YB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "fe8477a6-3c65-450a-cb9a-1c14b9919283"
      },
      "source": [
        "df[df['label']=='ham'].head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ham</td>\n",
              "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ham</td>\n",
              "      <td>Oh k...i'm watching here:)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                            message\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
              "6    ham  Even my brother is not like to speak with me. ...\n",
              "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "10   ham  I'm gonna be home soon and i don't want to tal...\n",
              "13   ham  I've been searching for the right words to tha...\n",
              "14   ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
              "16   ham                         Oh k...i'm watching here:)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPD8gGM6i8Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c5f82a8-1021-4819-9791-51debd727a31"
      },
      "source": [
        "lens = df.message.str.len()\n",
        "lens.mean(), lens.std(), lens.max()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80.61629576453697, 60.01559307992082, 910)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtA6xNi4kDGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a1a07af1-3df7-4142-b267-01dc923b9acd"
      },
      "source": [
        "lens.hist()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f286c997e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7N7yu0S1dbY",
        "colab_type": "text"
      },
      "source": [
        "Mostly short messages. In spam messages we can observe seeveral features:\n",
        " - More words in capital letters\n",
        " - More numbers\n",
        " - E-mail addresses \n",
        "\n",
        "We can use that features when preparing the data to tokenize spam messages right. \n",
        "\n",
        "In order to have more flexibility when applying the self-made naive bayes, i decided to make a function that will take preprocessed data as an input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtEo8dfc1gLu",
        "colab_type": "text"
      },
      "source": [
        "# **Part 1: DIY Naive Bayes classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq8skWvA2gan",
        "colab_type": "text"
      },
      "source": [
        "Define the function for Naive Bayes classifier with extra parameters. The algorithm that was used for the culculation is presented in [Speech and Language Precessing. Daniel Jurafsky and James H Martin, Chapter 4: Naive Bayes and Sentiment Classification](https://web.stanford.edu/~jurafsky/slp3/4.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JMPgzlQlOz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NBC_kfv(smslist, labellist, n_splits = 5, alpha = 1,metric = 'accuracy'):\n",
        "  '''A function takes as an input list messages (organized as list of lists, with tokinized and prepared data),\n",
        "  list of labels (values 0 or 1, where 1 is spam), number of splits, alpha parameter for smoothing and\n",
        "  metric to use: accuracy, f1-score, recall or precision'''\n",
        "  smslist = np.array(smslist)\n",
        "  labellist = np.array(labellist) \n",
        "  # create list for storing metrics \n",
        "  result = []\n",
        "  result_ham = []\n",
        "  result_spam = []\n",
        "  skf = StratifiedKFold(n_splits=n_splits)\n",
        "  # perform k-fold validation on observations, iterate over subsets\n",
        "  for train_index, test_index in skf.split(smslist,labellist):\n",
        "    X_train, X_test = smslist[train_index], smslist[test_index]\n",
        "    y_train, y_test = labellist[train_index], labellist[test_index]\n",
        "    # get the vocabulart of a subset\n",
        "    vocab = []\n",
        "    for sms in X_train:\n",
        "      for word in sms:\n",
        "        if word not in vocab:\n",
        "          vocab.append(word)\n",
        "    # culc the prior probability of classes\n",
        "    spam_prob = y_train.mean()\n",
        "    ham_prob = 1 - spam_prob\n",
        "    # create \"bigdocs\", containing all the words of each class\n",
        "    spam_sms = []\n",
        "    ham_sms = []\n",
        "    for i in range(len(y_train)):\n",
        "      if labellist[i] == 1:\n",
        "        spam_sms.append(X_train[i])\n",
        "      else:\n",
        "        ham_sms.append(X_train[i])\n",
        "    flat_spam_sms = [word1 for sms in spam_sms for word1 in sms]\n",
        "    flat_ham_sms = [word2 for sms in ham_sms for word2 in sms]\n",
        "    # make prediction over test sample\n",
        "    y_pred = []\n",
        "    # iterate over all massages in test sample\n",
        "    for sms in X_test:\n",
        "      test_spam_prob = np.log(spam_prob)\n",
        "      test_ham_prob = np.log(ham_prob)\n",
        "      # iterate over all words in a message\n",
        "      for word in sms:\n",
        "        # culculate probabilities of a sms appear in spam and ham classes\n",
        "        test_spam_prob += np.log(\n",
        "              ((flat_spam_sms.count(word)+alpha)/\n",
        "               (len(flat_spam_sms)+len(vocab)*alpha)))\n",
        "        test_ham_prob += np.log(\n",
        "              ((flat_ham_sms.count(word)+alpha)/\n",
        "               (len(flat_ham_sms)+len(vocab)*alpha)))\n",
        "      # compare the probabilities and append classes values\n",
        "      if test_spam_prob > test_ham_prob:\n",
        "        y_pred.append(1)\n",
        "      else:\n",
        "        y_pred.append(0)\n",
        "    # define metric scores\n",
        "    if metric == 'accuracy':\n",
        "      result.append(accuracy_score(y_test,y_pred))\n",
        "    elif metric == 'f1-score':\n",
        "      result_spam.append(classification_report(y_test,np.array(y_pred),output_dict = True)['1'][metric]) \n",
        "      result_ham.append(classification_report(y_test,np.array(y_pred),output_dict = True)['0'][metric])\n",
        "    elif metric == 'recall':\n",
        "      result_spam.append(classification_report(y_test,np.array(y_pred),output_dict = True)['1'][metric]) \n",
        "      result_ham.append(classification_report(y_test,np.array(y_pred),output_dict = True)['0'][metric])\n",
        "    elif metric == 'precision':\n",
        "      result_spam.append(classification_report(y_test,np.array(y_pred),output_dict = True)['1'][metric]) \n",
        "      result_ham.append(classification_report(y_test,np.array(y_pred),output_dict = True)['0'][metric])\n",
        "  if metric == 'accuracy':\n",
        "    return print(\"Accuracies for 5-fold validation are: \", [round(x,4) for x in result]) \n",
        "  else:\n",
        "    return print(metric,\"for spam class are: \", [round(x,4) for x in result_spam], '\\n',\n",
        "                 metric,\"for ham class are: \", [round(x,4) for x in result_ham])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ERV8GV2uEs",
        "colab_type": "text"
      },
      "source": [
        "Data preparation. I decided not to remove stop words and make stemming as in is not a good idea for spam detection task, as discussed in [Contributions to the Study of SMS Spam Filtering:\n",
        "New Collection and Results](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/doceng11.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaAu5EtMbGpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SMSs = df['message']\n",
        "labels = df['label']\n",
        "labels = [1 if i == 'spam' else 0 for i in labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zobfrn6r3q1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define punt removing function\n",
        "def remove_punctuation(x):\n",
        "  return x.translate(str.maketrans('', '', string.punctuation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ir6SNB63g1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply lowering, removing puntuation and tokenizing sms\n",
        "SMSs = SMSs.str.lower()\n",
        "SMSs = SMSs.apply(remove_punctuation)\n",
        "SMSs = SMSs.apply(word_tokenize)\n",
        "SMSs = SMSs.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDQ0LsZ_2r6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "600538ff-b732-4704-89ab-b75f973a0fae"
      },
      "source": [
        "# choose the metric and perform NBC, let's for example see at accuracy\n",
        "NBC_kfv(SMSs,labels, metric='accuracy')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies for 5-fold validation are:  [0.8368, 0.9283, 0.9623, 0.9767, 0.9749]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqcCjjoy7bet",
        "colab_type": "text"
      },
      "source": [
        "We can observe a pretty high accuracy score for almost all k-fold splits. The first one is a kind of outlier. Let's look, for example to recalls:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn0frXvu7wSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5af7c514-7060-4135-9778-d2ca681afa36"
      },
      "source": [
        "# choose the metric and perform NBC, let's for example see at accuracy\n",
        "NBC_kfv(SMSs,labels, metric='recall')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall for spam class are:  [0.1867, 0.7067, 0.8792, 0.9329, 0.953] \n",
            " recall for ham class are:  [0.9378, 0.9627, 0.9751, 0.9834, 0.9782]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3-sVG7g71--",
        "colab_type": "text"
      },
      "source": [
        "You can see very low spam recallin 1st split. I believe this happens due to the fact that in 1st fold there are \"less recognizable\" spam messages, than in other folds. Leet's change the number of splits, hopefully, it will smooth the situation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4EPgdcz8RWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "231174af-ece3-4655-ea19-3339d065bccf"
      },
      "source": [
        "# choose the metric and perform NBC, let's for example see at accuracy\n",
        "NBC_kfv(SMSs,labels, metric='recall', n_splits = 4)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall for spam class are:  [0.1183, 0.7594, 0.9091, 0.9572] \n",
            " recall for ham class are:  [0.9337, 0.9577, 0.9801, 0.9784]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTP3hgje8w4t",
        "colab_type": "text"
      },
      "source": [
        "Now, it didn't :( I give up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yrAe4_dt1Z8",
        "colab_type": "text"
      },
      "source": [
        "# **Part 2: use of sklearn Naive Bayes classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT4ybzzX8gez",
        "colab_type": "text"
      },
      "source": [
        "Now let's move on to built in sklearn naive bayes classifier. I found CountVerctorizer method in web and used it to quickly prepare the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay3qhGi6zC5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the data one more time\n",
        "df = pd.read_csv('SMSSpamCollection', encoding = 'latin_1', sep='\\t', header = None)\n",
        "df.columns = ['label', 'message']\n",
        "df['label'] = df.label.map({'ham':0,'spam':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp7ep1KruSlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data to train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'],df['label'],test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvjkEvhLwwRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize CountVectorizer method\n",
        "count_vectorizer = CountVectorizer()\n",
        "X_train = count_vectorizer.fit_transform(X_train)\n",
        "X_test = count_vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "044tSxD8zT7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2a5e9062-2541-49bb-d69f-4c25a88cfeba"
      },
      "source": [
        "# perform built in classifier and show the metrics\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train,y_train)\n",
        "predictions = naive_bayes.predict(X_test)\n",
        "print('Accuracy is ', round(accuracy_score(y_test, predictions),4))\n",
        "print('f1-score is ', round(f1_score(y_test, predictions),4))\n",
        "print('Recall of spam is ', round(recall_score(y_test, predictions),4))\n",
        "print('Precision of spam is ', round(precision_score(y_test, predictions),4))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is  0.9916\n",
            "f1-score is  0.9662\n",
            "Recall of spam is  0.9479\n",
            "Precision of spam is  0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp3mB1mp9gpb",
        "colab_type": "text"
      },
      "source": [
        "Well, for just one split built in function did better job that mine self-made. At least all the scores look higher than mine. Probably, CountVectorizer performed better that my data preprocessing. As i've mentions in the beginning, Spam messages have several special features, so the results of analysis are sensitive to the way you preprocessed you data."
      ]
    }
  ]
}